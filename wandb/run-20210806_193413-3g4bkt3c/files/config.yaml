wandb_version: 1

_current_progress_remaining:
  desc: null
  value: 1
_custom_logger:
  desc: null
  value: 'False'
_episode_num:
  desc: null
  value: 0
_last_episode_starts:
  desc: null
  value: '[ True]'
_last_obs:
  desc: null
  value: "[[[[0.00222222 0.         0.        ]\n   [0.         0.06       0.    \
    \    ]\n   [0.         0.06       0.        ]\n   [0.         0.04       0.  \
    \      ]\n   [0.         0.04       0.        ]\n   [0.00222222 0.06       0.\
    \        ]\n   [0.00222222 0.08       0.        ]\n   [0.00222222 0.1        0.\
    \        ]\n   [0.00222222 0.12       0.        ]\n   [0.00222222 0.12       0.\
    \        ]]]]"
_last_original_obs:
  desc: null
  value: None
_logger:
  desc: null
  value: <stable_baselines3.common.logger.Logger object at 0x000002570372CF70>
_n_updates:
  desc: null
  value: 0
_total_timesteps:
  desc: null
  value: 10000
_vec_normalize_env:
  desc: null
  value: None
_wandb:
  desc: null
  value:
    cli_version: 0.11.2
    code_path: code/agar/workspace.py
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    python_version: 3.8.8
    t:
      1:
      - 1
      - 3
      4: 3.8.8
      5: 0.11.2
      8:
      - 3
      - 5
action_noise:
  desc: null
  value: None
action_space:
  desc: null
  value: Box(-1.0, 1.0, (1,), float32)
algo:
  desc: null
  value: A2C
device:
  desc: null
  value: cuda
ent_coef:
  desc: null
  value: 0.0
env:
  desc: null
  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x0000025703701DC0>
env_name:
  desc: null
  value: agar
ep_info_buffer:
  desc: null
  value: deque([], maxlen=100)
ep_success_buffer:
  desc: null
  value: deque([], maxlen=100)
eval_env:
  desc: null
  value: None
gae_lambda:
  desc: null
  value: 1.0
gamma:
  desc: null
  value: 0.99
learning_rate:
  desc: null
  value: 0.0007
lr_schedule:
  desc: null
  value: <function constant_fn.<locals>.func at 0x00000257031A1940>
max_grad_norm:
  desc: null
  value: 0.5
n_envs:
  desc: null
  value: 1
n_steps:
  desc: null
  value: 5
normalize_advantage:
  desc: null
  value: 'False'
num_timesteps:
  desc: null
  value: 0
observation_space:
  desc: null
  value: Box(0.0, 1.0, (1, 10, 3), float32)
policy:
  desc: null
  value: "CustomPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten):\
    \ Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor): MlpExtractor(\n  \
    \  (shared_net): Sequential()\n    (policy_net): Sequential(\n      (0): Linear(in_features=30,\
    \ out_features=10, bias=True)\n      (1): Tanh()\n    )\n    (value_net): Sequential(\n\
    \      (0): Linear(in_features=30, out_features=10, bias=True)\n      (1): Tanh()\n\
    \    )\n  )\n  (action_net): Linear(in_features=10, out_features=1, bias=True)\n\
    \  (value_net): Linear(in_features=10, out_features=1, bias=True)\n)"
policy_class:
  desc: null
  value: <class '__main__.CustomPolicy'>
policy_kwargs:
  desc: null
  value: '{''optimizer_class'': <class ''torch.optim.rmsprop.RMSprop''>, ''optimizer_kwargs'':
    {''alpha'': 0.99, ''eps'': 1e-05, ''weight_decay'': 0}}'
policy_type:
  desc: null
  value: MlpPolicy
rollout_buffer:
  desc: null
  value: <stable_baselines3.common.buffers.RolloutBuffer object at 0x0000025703701CD0>
sde_sample_freq:
  desc: null
  value: -1
seed:
  desc: null
  value: None
start_time:
  desc: null
  value: 1628242459.224925
tensorboard_log:
  desc: null
  value: None
total_timesteps:
  desc: null
  value: 25000
use_sde:
  desc: null
  value: 'False'
verbose:
  desc: null
  value: 1
vf_coef:
  desc: null
  value: 0.5
